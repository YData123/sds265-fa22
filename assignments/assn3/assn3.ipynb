{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Machine Learning: Assignment 3\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "Assignment 3 is due Tuesday, November 1 at 11:59pm. Late work will not be accepted as per the course policies (see the Syllabus and Course policies on [Canvas](https://canvas.yale.edu).\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on [Canvas](https://canvas.yale.edu).  You can also post questions or start discussions on [Ed Discussion](https://edstem.org/us/courses/9209/discussion/). The problems are broken up into steps that should help you to make steady progress.\n",
    "\n",
    "**Submission:**\n",
    "\n",
    "Submit your assignment as a .pdf on Gradescope, and as a .ipynb on Canvas. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. Note: When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. This will allow graders to find your complete solution to each problem.\n",
    "\n",
    "To produce the .pdf, please do the following in order to preserve the cell structure of the notebook:  \n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "2.  Under \"Download as\", select \"HTML (.html)\"\n",
    "3.  After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "4.  From the print window, select the option to save as a .pdf\n",
    "\n",
    "**Topics**\n",
    "1. Random forests\n",
    "2. Principal components analysis                                                               \n",
    "3. Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Seeing the random forests for the trees (25 points)\n",
    "\n",
    "This problem is based on the `diabetes` dataset from the `sklearn` package. Please read about the dataset at [https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset). We will predict the response, which is a quantitative measure of diabetes progression one year after baseline, using regression trees and random forests.\n",
    "\n",
    "The following cell imports the dataset as `diabetes` and names the predictor variables `diabetes_x` and the response `diabetes_y`. Just run this cell, do not modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_x = diabetes.data\n",
    "diabetes_y = diabetes.target\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Building a simple regression tree\n",
    "\n",
    "To start, you will *manually* build a regression tree using only two of the predictor variables: `bmi` and `s5`. To keep things simple, build a tree that has exactly three nodes and four leaves. So, the data is split into two parts initially and then each of those parts is again split one more time. At each node you will need to evaluate each possible splitting point for both `bmi` and `s5` and pick the one that minimizes the RSS.\n",
    "\n",
    "When you have built the regression tree, create a scatter plot of `s5` versus `bmi`, color-coded by the response variable. In this plot, use vertical and horizontal lines to indicate the regions that your tree splits the data into. You may find the functions `plt.hlines()` and `plt.vlines()` to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- please write your answer here. -- ## \n",
    "# extract the data\n",
    "bmi = diabetes_x[:,2]\n",
    "s5 = diabetes_x[:,8]\n",
    "rss_bmi = []\n",
    "rss_s5 = []\n",
    "\n",
    "# we put a wrapper on the np.mean function to avoid warnings from taking the average of an empty list\n",
    "def average(x):\n",
    "    if len(x) == 0:\n",
    "        return(0.0)\n",
    "    else:\n",
    "        return(np.mean(x))\n",
    "\n",
    "# the following starter code finds the best splits for bmi and bp at the root\n",
    "for i in range(len(bmi)):\n",
    "    left = np.where(bmi <= bmi[i])[0]\n",
    "    right = np.where(bmi > bmi[i])[0]\n",
    "    rss_bmi.append(np.sum((diabetes_y[left] - average(diabetes_y[left]))**2) + \n",
    "                   np.sum((diabetes_y[right] - average(diabetes_y[right]))**2))\n",
    "    left = np.where(s5 <= s5[i])[0]\n",
    "    right = np.where(s5 > s5[i])[0]\n",
    "    rss_s5.append(np.sum((diabetes_y[left] - average(diabetes_y[left]))**2) + \n",
    "                  np.sum((diabetes_y[right] - average(diabetes_y[right]))**2))\n",
    "    \n",
    "best_bmi_cut = np.argmin(rss_bmi)\n",
    "best_s5_cut = np.argmin(rss_s5)\n",
    "\n",
    "# You should feel free to rewrite the above code in any way that suits you.\n",
    "# Now complete the code to make the best split, and then split each child node, \n",
    "# and then visualize the tree, showing the four leaf rectangles in the space s5 vs. bmi \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some starter code that you can use to show the four rectangles defined by the leaves. Modify this to use the regions defined by the decision tree above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bmi, s5, c = diabetes_y)\n",
    "plt.ylabel(\"S5\", fontsize=14)\n",
    "plt.xlabel(\"BMI\", fontsize=14)\n",
    "plt.hlines(0, xmin=np.min(bmi), xmax=np.max(bmi), colors='r')\n",
    "plt.vlines(0, ymin=np.min(s5), ymax=np.max(bmi), colors='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fitting a full regression tree\n",
    "\n",
    "Now build a tree that uses all the predictor variables, has a more flexible structure, and is validated with a test set. Split the full dataset into a training set and a test set of equal size (50/50). Fit a regression tree to the training set using the function `DecisionTreeRegressor` from `sklearn.tree`. For now, use your best judgment to choose parameters for tree complexity; we will use cross-validation to choose parameters in later parts of this problem set. Some starter code is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# regr = tree.DecisionTreeRegressor().fit() \n",
    "# tree parameters go inside the first set of parentheses and the\n",
    "# training data goes in the second set of parenthases. Check the \n",
    "# documentation for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plotting the tree\n",
    "\n",
    "Plot your regression tree. To do so, just execute the cell below; no\n",
    "need to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(regr, filled=True, feature_names=diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluation\n",
    "\n",
    "Interpret your regression tree. What are some examples of variables that seem to correspond to higher or lower measures of diabetes progression? What is the MSE of the model using the test set? The `.predict` method for your model can help with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Using random forests\n",
    "\n",
    "Finally, we will grow random forests to analyze the data,\n",
    "using the `RandomForestRegressor` function from `sklearn.ensemble`. Again, please use your best judgment to choose the initial parameters for tree complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# Here is an example of how to use the random forest function in sklearn.ensemble.\n",
    "# The code below assumes that the training inputs and responses are loaded in the variables train_x and train_y\n",
    "# and that the test predictor variables are in test_x\n",
    "\n",
    "# dtr = ensemble.RandomForestRegressor(min_samples_leaf=15, max_features=m)\n",
    "# regr = dtr.fit(train_x, train_y)\n",
    "# pred_y = regr.predict(test_x)\n",
    "# mse = np.mean(np.square(test_y-pred_y))\n",
    "\n",
    "## -- please write your answer here. -- ## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions to compare the performance of random forests to a single regression tree.\n",
    "\n",
    "1. What test MSE do you obtain, and how does it compare to the test MSE of the regression tree above? \n",
    "\n",
    "1. According to the model, which variables are most important in predicting diabetes progression? (The `.feature_importances_` method of the model may help with this.)\n",
    "\n",
    "1. Plot the MSE of the prediction against $m$, the number of variables considered at each split.\n",
    "\n",
    "1. Comment on the plot you created and if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your answers here, using a mix of Markdown and code, as appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: PCA: Penguin Culmen Analysis (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit our flightless friends with the new tools we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell to import needed packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell to read in the data\n",
    "\n",
    "df = pd.read_csv('https://github.com/YData123/sds265-fa22/raw/master/assignments/assn2/penguins.csv')\n",
    "df = df.drop(columns=['index','year','island'])\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# encode the labels\n",
    "species = list(set(df['species']))\n",
    "df['class'] = LabelEncoder().fit_transform(df['species'])\n",
    "sex = [int(list(df['sex'])[j]=='male') for j in range(len(df))]\n",
    "df['sex'] = sex\n",
    "df = df.drop(columns=['species'])\n",
    "\n",
    "y = np.array(df['class'])\n",
    "X = df.copy()\n",
    "X = X.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell to standardize\n",
    "\n",
    "for i in range(5):\n",
    "    X.iloc[:,i] = (X.iloc[:,i]-np.mean(X.iloc[:,i]))/np.std(X.iloc[:,i])\n",
    "\n",
    "print(f\"X is {X.shape[0]} rows with {X.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Run PCA\n",
    "\n",
    "In the next cell, carry out Principle Component Analysis to reduce the data from 5 dimensions to 2.\n",
    "\n",
    "Let `pv1` be the first principal vector and let `pv2` be the second principal vector. Let `pcs` be the projection of the data onto the first two principal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pv1 =  # your code here\n",
    "pv2 =  # your code here\n",
    "pcs =  # your code here\n",
    "\n",
    "principalX = pd.DataFrame(data = pcs, columns = ['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Principle Component Analysis\n",
    "\n",
    "The next cell plots the principal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "\n",
    "plt.bar(range(5), pv1)\n",
    "plt.xticks(range(5), X.columns, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(range(5), pv2)\n",
    "plt.xticks(range(5), X.columns, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the first two principle vectors orthogonal? Write code to check and also explain conceptually.\n",
    "\n",
    "Looking at the plot, what are the first two principle components capturing, in terms of the original features we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your markdown here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "\n",
    "plt.scatter(principalX.iloc[:, 0], principalX.iloc[:, 1], c = y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is being plotted in this cell above? If you are to add an xlabel and ylabel, what would you call them?\n",
    "\n",
    "Can you explain why there are pretty much 6 clusters in the plot?\n",
    "\n",
    "Recall when we plotted using two features of your choice in assignment 2. How are these different and similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your markdoen here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualization with decision boundries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to add the decision boundries to the plot. (Similar to what we did in assignment 2, but this time using the first 2 principle components as x and y.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "# the function will again help you plot the decision boundries\n",
    "\n",
    "def plot_decision_boundaries(X, y, lr, error):\n",
    "    X2 = np.array(X)\n",
    "    b = lr.intercept_\n",
    "    beta = lr.coef_.T\n",
    "    colors = ['orange', 'pink', 'lightgreen']\n",
    "    h = 0.015\n",
    "    x_min, x_max = X2[:, 0].min() - .5, X2[:, 0].max() + .5\n",
    "    y_min, y_max = X2[:, 1].min() - .5, X2[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = np.dot(np.c_[xx.ravel(), yy.ravel()], beta) + b\n",
    "    Z = np.argmax(Z, axis=1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.contourf(xx, yy, Z, levels=[0,.5,1.5,2.5], colors=colors, alpha=0.5)\n",
    "    for c in range(3):\n",
    "        mask = (y==c)\n",
    "        plt.scatter(X2[np.array(mask),0], X2[np.array(mask),1], color=colors[c], label=species[c])\n",
    "\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('error rate: %.2f' % error)\n",
    "    plt.xlabel(X.columns[0])\n",
    "    plt.ylabel(X.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you think the model performed comparing to the models you ran in assignment 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your markdown here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: PCA for dimension reduction (20 points)\n",
    "\n",
    "In this problem you will approximately reconstruct images by simplifying them to multiples of a few principal components.\n",
    "\n",
    "Note: When you display the images, use the color map `cmap=plt.cm.gray.reversed()` for MNIST and Fashion MNIST and use `cmap=plt.cm.gray` for the face data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "\n",
    "Pick a random seed in the next cell to select a random image of a handwritten $0$ from the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fafe45d76d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x, y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x = x.reshape([60000, 28*28])\n",
    "zeros = np.where(y==0)[0]\n",
    "x = x[zeros,:]\n",
    "y = y[zeros]\n",
    "np.random.seed(265) # put your seed here\n",
    "my_image = np.random.randint(0, len(y), size=1)\n",
    "\n",
    "plt.imshow(x[my_image,:].reshape((28,28)), cmap=plt.cm.gray.reversed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $k = 0, 10, 20, ...,100$, use $k$ principal components for MNIST $0$'s to approximately reconstruct the image selected above. Display the reconstruction for each value of $k$. To display the set of images compactly, you may want to use subplot, as shown in the starter code for Problem 3(c) below. You may also refer to the examples in this document: https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.subplots.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Markdown Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "\n",
    "Repeat Part 1, but this time for the dresses in the Fashion-MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fafc541b390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x, y), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x = x.reshape([60000, 28*28])\n",
    "zeros = np.where(y==3)[0]\n",
    "x = x[zeros,:]\n",
    "y = y[zeros]\n",
    "np.random.seed(265) #put your seed here\n",
    "my_image = np.random.randint(0, len(y), size=1)\n",
    "\n",
    "plt.imshow(x[my_image,:].reshape((28,28)), cmap=plt.cm.gray.reversed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Markdown Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "\n",
    "Do the same thing as in Parts 1 and 2, this time reconstructing an image of Gerhard Schroeder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "lfw_people.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lfw_people.data\n",
    "y = lfw_people.target\n",
    "zeros = np.where(y==4)[0]\n",
    "x = x[zeros,:]\n",
    "y = y[zeros]\n",
    "np.random.seed(265) #put your seed here\n",
    "my_image = np.random.randint(0, len(y), size=1)\n",
    "\n",
    "\n",
    "plt.imshow(x[my_image,:].reshape((50,37)), cmap=plt.cm.gray)#, cmap=plt.cm.gray.reversed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Markdown Here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
